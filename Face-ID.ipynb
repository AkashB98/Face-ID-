{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1st program to check face \n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##2nd program\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('download.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.imshow(img, cmap = 'gray', interpolation = 'bicubic')\n",
    "plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "plt.plot([200,300,400],[100,200,300],'c', linewidth=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to plot image on graph\n",
    "plt.imshow(img, cmap='gray', interpolation='bicubic')\n",
    "plt.plot([50,100], [80,100], 'c', linewidth=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('downloadgray.png',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('download.jpg',cv2.IMREAD_COLOR)\n",
    "cv2.line(img,(0,0),(200,300),(255,255,255),50)\n",
    "cv2.rectangle(img,(500,250),(1000,500),(0,0,255),15)\n",
    "cv2.circle(img,(447,63), 63, (0,255,0), -1)\n",
    "pts = np.array([[100,50],[200,300],[700,200],[500,100]], np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "cv2.polylines(img, [pts], True, (0,255,255), 3)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img,'OpenCV Tuts!',(10,500), font, 6, (200,255,155), 13, cv2.LINE_AA)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('download.jpg',cv2.IMREAD_COLOR)\n",
    "px = img[55,55]\n",
    "img[55,55] = [255,255,255]\n",
    "px = img[55,55]\n",
    "print(px)\n",
    "px = img[100:150,100:150]\n",
    "print(px)\n",
    "img[100:150,100:150] = [255,255,255]\n",
    "print(img.shape)\n",
    "print(img.size)\n",
    "print(img.dtype)\n",
    "watch_face = img[37:111,107:194]\n",
    "img[0:74,0:87] = watch_face\n",
    "\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAPORTING 2 IMAGES\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load two images\n",
    "img1 = cv2.imread('mario.png')\n",
    "img2 = cv2.imread('mario.png')\n",
    "\n",
    "# I want to put logo on top-left corner, So I create a ROI\n",
    "rows,cols,channels = img2.shape\n",
    "roi = img1[0:rows, 0:cols ]\n",
    "\n",
    "# Now create a mask of logo and create its inverse mask\n",
    "img2gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# add a threshold\n",
    "ret, mask = cv2.threshold(img2gray, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "# Now black-out the area of logo in ROI\n",
    "img1_bg = cv2.bitwise_and(roi,roi,mask = mask_inv)\n",
    "\n",
    "# Take only region of logo from logo image.\n",
    "img2_fg = cv2.bitwise_and(img2,img2,mask = mask)\n",
    "\n",
    "dst = cv2.add(img1_bg,img2_fg)\n",
    "img1[0:rows, 0:cols ] = dst\n",
    "\n",
    "cv2.imshow('res',img1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FOR BLURRING IMAGE\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lower_red = np.array([30,150,50])\n",
    "    upper_red = np.array([255,255,180])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    kernel = np.ones((15,15),np.float32)/225\n",
    "    smoothed = cv2.filter2D(res,-1,kernel)\n",
    "    cv2.imshow('Original',frame)\n",
    "    cv2.imshow('Averaging',smoothed)\n",
    "\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##MOrphological conversion of image \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "\n",
    "    _, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lower_red = np.array([30,150,50])\n",
    "    upper_red = np.array([255,255,180])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    cv2.imshow('Original',frame)\n",
    "    edges = cv2.Canny(frame,100,200)\n",
    "    cv2.imshow('Edges',edges)\n",
    "\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FOR FINDING CORNERS OF IMAGE\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('opencv-corner-detection-sample.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray)\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(gray, 100, 0.01, 10)\n",
    "corners = np.int0(corners)\n",
    "for corner in corners:\n",
    "    x,y = corner.ravel()\n",
    "    cv2.circle(img,(x,y),3,255,-1)\n",
    "    \n",
    "cv2.imshow('Corner',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#HELPS YOU TO READ STRAIGHT FROM SITE \n",
    "\n",
    "import pandas, scipy, numpy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#HELPS YOU TO READ STRAIGHT FROM SITE \n",
    "df=pandas.read_csv( 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv ',sep=';')\n",
    "array=df.values\n",
    "#Separating data into input and output components\n",
    "x=array[:,0:8]\n",
    "y=array[:,8]\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "rescaledX=scaler.fit_transform(x)\n",
    "numpy.set_printoptions(precision=3) #Setting precision for the output\n",
    "rescaledX[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.528,  0.962, -1.391, -0.453, -0.244, -0.466, -0.379,  0.558],\n",
       "       [-0.299,  1.967, -1.391,  0.043,  0.224,  0.873,  0.624,  0.028],\n",
       "       [-0.299,  1.297, -1.186, -0.169,  0.096, -0.084,  0.229,  0.134],\n",
       "       [ 1.655, -1.384,  1.484, -0.453, -0.265,  0.108,  0.412,  0.664],\n",
       "       [-0.528,  0.962, -1.391, -0.453, -0.244, -0.466, -0.379,  0.558]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler().fit(x)\n",
    "rescaledX=scaler.transform(x)\n",
    "rescaledX[0:5,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
